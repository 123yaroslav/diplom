{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import causalpy \n",
    "import seaborn as sns\n",
    "from patsy import build_design_matrices, dmatrices\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from library.synthetic_control import *\n",
    "from library.data_generator import generate_gaussian_process_data\n",
    "from library.synthetic_did import SyntheticDIDModel\n",
    "from library.synthetic_bayes import WeightedSumFitter\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = pd.read_parquet('data/data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bayes = real_data.pivot(index='time', columns='shopno', values='preprocessed_avg_delivery').reset_index(drop=True).rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_gp_synthetic_model(t, y, X, use_covariates=True):\n",
    "    y = np.asarray(y).flatten()\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        t_shared = pm.MutableData(\"t\", t.reshape(-1, 1))\n",
    "\n",
    "        if use_covariates:\n",
    "            X_shared = pm.MutableData(\"X\", X)\n",
    "            beta_lin   = pm.Dirichlet(\"beta_lin\", a=np.ones(X.shape[1]))\n",
    "            intercept  = pm.Normal(\"intercept\", mu=0, sigma=5)\n",
    "            linear_term = intercept + pm.math.dot(X_shared, beta_lin)\n",
    "        else:\n",
    "            linear_term = 0\n",
    "\n",
    "        sigma_f = pm.HalfNormal(\"sigma_f\", sigma=2)\n",
    "        ell     = pm.HalfNormal(\"ell\", sigma=2)\n",
    "        cov_func = sigma_f**2 * pm.gp.cov.ExpQuad(1, ell)\n",
    "        gp = pm.gp.Latent(cov_func=cov_func)\n",
    "        gp_effect = gp.prior(\"gp_effect\", X=t_shared)\n",
    "\n",
    "        mu = pm.Deterministic(\"mu\", linear_term + gp_effect)\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=2)\n",
    "\n",
    "        y_shared = pm.MutableData(\"y\", y)   \n",
    "        pm.Normal(\"y_hat\", mu=mu, sigma=sigma, observed=y_shared)\n",
    "\n",
    "        idata = pm.sample(   draws=300,\n",
    "                             tune=400,\n",
    "                             chains=2,\n",
    "                             return_inferencedata=True,\n",
    "                             target_accept=0.95,\n",
    "                             random_seed=42 )\n",
    "        posterior_predictive = pm.sample_posterior_predictive(idata)\n",
    "\n",
    "    return idata, posterior_predictive, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_bayesian_synthetic_control_analysis(\n",
    "    model_name: str,\n",
    "    data: pd.DataFrame,\n",
    "    output_dir: str = \"results\",\n",
    "    metric: str = \"summary\",\n",
    "    T0: int = 70,\n",
    "    effect_sizes: list = None,\n",
    "    hdi_prob: float = 0.97\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    if effect_sizes is None:\n",
    "        effect_sizes = [0, 5, 10, 15, 20]\n",
    "\n",
    "    units = data.columns.tolist()\n",
    "    results = []\n",
    "\n",
    "    fp_flags = []\n",
    "    for response in units:\n",
    "        treatment_time = T0\n",
    "        predictors = [c for c in units if c != response]\n",
    "        formula    = f\"{response} ~ \" + \" + \".join(predictors)\n",
    "        datapre = data_bayes[data_bayes.index < treatment_time]\n",
    "        datapost = data_bayes[data_bayes.index >= treatment_time]\n",
    "        y, X = dmatrices(formula, datapre)\n",
    "        pre_y, pre_X = np.asarray(y), np.asarray(X)\n",
    "        (new_y, new_x) = build_design_matrices(\n",
    "            [y.design_info, X.design_info], datapost\n",
    "        )\n",
    "        post_X = np.asarray(new_x)\n",
    "        post_y = np.asarray(new_y)\n",
    "        del y, X\n",
    "        y_pre_dm, X_pre_dm = dmatrices(formula, datapre)\n",
    "        design_infos = [y_pre_dm.design_info, X_pre_dm.design_info]\n",
    "        y_pre = np.asarray(y_pre_dm)   \n",
    "        X_pre = np.asarray(X_pre_dm)  \n",
    "        (new_y_dm, new_x_dm) = build_design_matrices(design_infos, datapost)\n",
    "        y_post = np.asarray(new_y_dm)   \n",
    "        X_post = np.asarray(new_x_dm)   \n",
    "        y_pre_model = y_pre.flatten()  \n",
    "        pre_t = np.arange(y_pre_model.shape[0]) \n",
    "        idata, posterior_predictive_pre, model = bayesian_gp_synthetic_model(\n",
    "            pre_t, y_pre, X_pre, use_covariates=True\n",
    "        )\n",
    "        idata, posterior_predictive_pre, model = bayesian_gp_synthetic_model(pre_t, y_pre_model, X_pre, use_covariates=True)\n",
    "        y_post_model = y_post.flatten()\n",
    "        post_t = np.arange(pre_t[-1] + 1, pre_t[-1] + 1 + y_post_model.shape[0])\n",
    "        with model:\n",
    "            pm.set_data(new_data={\"t\": post_t.reshape(-1, 1), \"X\": X_post, \"y\": y_post_model})\n",
    "            posterior_predictive_post = pm.sample_posterior_predictive(trace=idata, var_names=[\"y_hat\"])\n",
    "        post_posterior_mean = (\n",
    "            posterior_predictive_post.posterior_predictive[\"y_hat\"][:, :, :T0]\n",
    "            .stack(samples=(\"chain\", \"draw\"))\n",
    "            .mean(axis=1)\n",
    "        )\n",
    "        actual_post = data_bayes.loc[datapost.index, f\"{response}\"].values\n",
    "        att_time_series = actual_post - post_posterior_mean\n",
    "        y_hat_pre = posterior_predictive_pre.posterior_predictive[\"y_hat\"]\n",
    "        y_hat_post = posterior_predictive_post.posterior_predictive[\"y_hat\"]\n",
    "        pre_posterior_mean = y_hat_pre.stack(samples=(\"chain\", \"draw\")).mean(axis=1).values\n",
    "        post_posterior_mean = y_hat_post.stack(samples=(\"chain\", \"draw\")).mean(axis=1).values\n",
    "        posterior_mean_full = np.concatenate([pre_posterior_mean, post_posterior_mean])\n",
    "        att_mean = np.mean(att_time_series)\n",
    "        actual_post = data_bayes.loc[datapost.index, f\"{response}\"].values\n",
    "        att_time_series = actual_post - post_posterior_mean\n",
    "        att_mean = np.mean(att_time_series)\n",
    "        low, high = az.summary(posterior_predictive_post.posterior_predictive)[['hdi_3%', 'hdi_97%']].mean()\n",
    "        fp_flags.append((low > 0) or (high < 0))\n",
    "    type1_error = sum(fp_flags) / len(units)\n",
    "    print(f\"Type I error (false-positive rate): {type1_error:.3f}\\n\")\n",
    "\n",
    "    for eff in effect_sizes[1:]:\n",
    "        fn_flags = []\n",
    "        ests = []\n",
    "        for response in units:\n",
    "\n",
    "            treatment_time = T0\n",
    "            predictors = [c for c in units if c != response]\n",
    "            formula    = f\"{response} ~ \" + \" + \".join(predictors)\n",
    "            datapre = data_bayes[data_bayes.index < treatment_time]\n",
    "            datapost = data_bayes[data_bayes.index >= treatment_time]\n",
    "            y, X = dmatrices(formula, datapre)\n",
    "            pre_y, pre_X = np.asarray(y), np.asarray(X)\n",
    "            (new_y, new_x) = build_design_matrices(\n",
    "                [y.design_info, X.design_info], datapost\n",
    "            )\n",
    "            post_X = np.asarray(new_x)\n",
    "            post_y = np.asarray(new_y)\n",
    "            del y, X\n",
    "            y_pre_dm, X_pre_dm = dmatrices(formula, datapre)\n",
    "            design_infos = [y_pre_dm.design_info, X_pre_dm.design_info]\n",
    "            y_pre = np.asarray(y_pre_dm)   \n",
    "            X_pre = np.asarray(X_pre_dm)  \n",
    "            (new_y_dm, new_x_dm) = build_design_matrices(design_infos, datapost)\n",
    "            y_post = np.asarray(new_y_dm)   \n",
    "            X_post = np.asarray(new_x_dm)   \n",
    "            y_pre_model = y_pre.flatten()  \n",
    "            pre_t = np.arange(y_pre_model.shape[0]) \n",
    "            idata, posterior_predictive_pre, model = bayesian_gp_synthetic_model(\n",
    "                pre_t, y_pre, X_pre, use_covariates=True\n",
    "            )\n",
    "            idata, posterior_predictive_pre, model = bayesian_gp_synthetic_model(pre_t, y_pre_model, X_pre, use_covariates=True)\n",
    "            y_post_model = y_post.flatten()\n",
    "            post_t = np.arange(pre_t[-1] + 1, pre_t[-1] + 1 + y_post_model.shape[0])\n",
    "            with model:\n",
    "                pm.set_data(new_data={\"t\": post_t.reshape(-1, 1), \"X\": X_post, \"y\": y_post_model})\n",
    "                posterior_predictive_post = pm.sample_posterior_predictive(trace=idata, var_names=[\"y_hat\"])\n",
    "            post_posterior_mean = (\n",
    "                posterior_predictive_post.posterior_predictive[\"y_hat\"][:, :, :T0]\n",
    "                .stack(samples=(\"chain\", \"draw\"))\n",
    "                .mean(axis=1)\n",
    "            )\n",
    "            actual_post = data_bayes.loc[datapost.index, f\"{response}\"].values\n",
    "            att_time_series = actual_post - post_posterior_mean\n",
    "            y_hat_pre = posterior_predictive_pre.posterior_predictive[\"y_hat\"]\n",
    "            y_hat_post = posterior_predictive_post.posterior_predictive[\"y_hat\"]\n",
    "            pre_posterior_mean = y_hat_pre.stack(samples=(\"chain\", \"draw\")).mean(axis=1).values\n",
    "            post_posterior_mean = y_hat_post.stack(samples=(\"chain\", \"draw\")).mean(axis=1).values\n",
    "            posterior_mean_full = np.concatenate([pre_posterior_mean, post_posterior_mean])\n",
    "            att_mean = np.mean(att_time_series)\n",
    "            actual_post = data_bayes.loc[datapost.index, f\"{response}\"].values\n",
    "            att_time_series = actual_post - post_posterior_mean\n",
    "            att_mean = np.mean(att_time_series)\n",
    "            low, high = az.summary(posterior_predictive_post.posterior_predictive)[['hdi_3%', 'hdi_97%']].mean()\n",
    "\n",
    "            mean_eff = 1\n",
    "\n",
    "            detected = (low > 0) or (high < 0)\n",
    "            fn_flags.append(not detected)\n",
    "            ests.append(mean_eff)\n",
    "        type2_error = sum(fn_flags) / len(units)\n",
    "        errors = np.array(ests) - eff\n",
    "        rmspe = np.sqrt(np.mean(errors ** 2))\n",
    "        print(f\"=== Effect {eff}% ===\")\n",
    "        print(f\"Type II error (false-negative rate): {type2_error:.3f}\")\n",
    "        print(f\"RMSPE of effect estimates: {rmspe:.3f}\\n\")\n",
    "        results.append({\n",
    "            \"effect_size\": eff,\n",
    "            \"type1_error\": type1_error,\n",
    "            \"type2_error\": type2_error,\n",
    "            \"rmspe\": rmspe,\n",
    "        })\n",
    "\n",
    "    summary = pd.DataFrame(results)\n",
    "    print(\"=== Summary ===\")\n",
    "    print(summary.to_string(index=False))\n",
    "\n",
    "    result_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"metric\": metric,\n",
    "        \"summary\": summary.to_dict(orient=\"records\")\n",
    "    }\n",
    "    filename = os.path.join(f\"summary_{model_name}_{metric}.json\")\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result_dict, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bayes = real_data.pivot(index='time', columns='shopno', values='preprocessed_avg_delivery').reset_index(drop=True).rename_axis(None, axis=1)\n",
    "\n",
    "run_bayesian_synthetic_control_analysis(\n",
    "    model_name=\"BayesianSyntheticControlGP\",\n",
    "    data=data_bayes,\n",
    "    metric=\"preprocessed_avg_delivery\",\n",
    "    T0=70\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bayes = real_data.pivot(index='time', columns='shopno', values='preprocessed_orders_per_courier').reset_index(drop=True).rename_axis(None, axis=1)\n",
    "\n",
    "run_bayesian_synthetic_control_analysis(\n",
    "    model_name=\"BayesianSyntheticControlGP\",\n",
    "    data=data_bayes,\n",
    "    metric=\"preprocessed_orders_per_courier\",\n",
    "    T0=70\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bayes = real_data.pivot(index='time', columns='shopno', values='preprocessed_distance').reset_index(drop=True).rename_axis(None, axis=1)\n",
    "\n",
    "run_bayesian_synthetic_control_analysis(\n",
    "    model_name=\"BayesianSyntheticControlGP\",\n",
    "    data=data_bayes,\n",
    "    metric=\"preprocessed_distance\",\n",
    "    T0=70\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bayes = real_data.pivot(index='time', columns='shopno', values='preprocessed_avg_collection_time').reset_index(drop=True).rename_axis(None, axis=1)\n",
    "\n",
    "run_bayesian_synthetic_control_analysis(\n",
    "    model_name=\"BayesianSyntheticControlGP\",\n",
    "    data=data_bayes,\n",
    "    metric=\"preprocessed_avg_collection_time\",\n",
    "    T0=70\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bayes = real_data.pivot(index='time', columns='shopno', values='preprocessed_percent_late').reset_index(drop=True).rename_axis(None, axis=1)\n",
    "\n",
    "run_bayesian_synthetic_control_analysis(\n",
    "    model_name=\"BayesianSyntheticControlGP\",\n",
    "    data=data_bayes,\n",
    "    metric=\"preprocessed_percent_late\",\n",
    "    T0=70\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
